{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\n%matplotlib inline\n\n# import cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\nimport datetime\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "2f098545df55756a4af001cb1f06a425d6c228ca"
      },
      "cell_type": "code",
      "source": "# Set some parameters\nimg_size_ori = 101\nimg_size_target = 101\nim_width = 101\nim_height = 101\nim_chan = 1\nbasicpath = '../input/'\npath_train = basicpath + 'train/'\npath_test = basicpath + 'test/'\n\npath_train_images = path_train + 'images/'\npath_train_masks = path_train + 'masks/'\npath_test_images = path_test + 'images/'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33fb13eb8045a5465275427e42af57e804c00db1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Loading of training/testing ids and depths\n\ntrain_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\nlen(train_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b17f5f08492c3d21dbe38a68b7b6031b18334f4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n\ntrain_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n\ntrain_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a80a6cb785fc05a942bded5eddd8c023d2823aed"
      },
      "cell_type": "code",
      "source": "# Create train/validation split stratified by salt coverage\n\nids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    np.array(train_df.masks.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "55afe0f4f65cda9ac43124098f0f3f4e9084718f"
      },
      "cell_type": "code",
      "source": "ACTIVATION = \"relu\"\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = BatchNormalization()(x)\n    if activation == True:\n        x = Activation(ACTIVATION)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = Activation(ACTIVATION)(blockInput)\n    x = BatchNormalization()(x)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    return x",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "cc20d9ee66109c39a17df4efaf023c368da245f7"
      },
      "cell_type": "code",
      "source": "def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return score\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\ndef bce_logdice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n\ndef weighted_bce_loss(y_true, y_pred, weight):\n    epsilon = 1e-7\n    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n    logit_y_pred = K.log(y_pred / (1. - y_pred))\n    loss = weight * (logit_y_pred * (1. - y_true) + \n                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n    return K.sum(loss) / K.sum(weight)\n\ndef weighted_dice_loss(y_true, y_pred, weight):\n    smooth = 1.\n    w, m1, m2 = weight, y_true, y_pred\n    intersection = (m1 * m2)\n    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n    loss = 1. - K.sum(score)\n    return loss\n\ndef weighted_bce_dice_loss(y_true, y_pred):\n    y_true = K.cast(y_true, 'float32')\n    y_pred = K.cast(y_pred, 'float32')\n    # if we want to get same size of output, kernel size must be odd\n    averaged_mask = K.pool2d(\n            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n    weight = K.ones_like(averaged_mask)\n    w0 = K.sum(weight)\n    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n    w1 = K.sum(weight)\n    weight *= (w0 / w1)\n    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n    return loss\n\n\n\"\"\"\nLovasz-Softmax and Jaccard hinge loss in Tensorflow\nMaxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n\"\"\"\n\nfrom __future__ import print_function, division\n\nimport tensorflow as tf\nimport numpy as np\n\n\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    gts = tf.reduce_sum(gt_sorted)\n    intersection = gts - tf.cumsum(gt_sorted)\n    union = gts + tf.cumsum(1. - gt_sorted)\n    jaccard = 1. - intersection / union\n    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n    return jaccard\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        def treat_image(log_lab):\n            log, lab = log_lab\n            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n            log, lab = flatten_binary_scores(log, lab, ignore)\n            return lovasz_hinge_flat(log, lab)\n        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n        loss = tf.reduce_mean(losses)\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n\n    def compute_loss():\n        labelsf = tf.cast(labels, logits.dtype)\n        signs = 2. * labelsf - 1.\n        errors = 1. - logits * tf.stop_gradient(signs)\n        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n        gt_sorted = tf.gather(labelsf, perm)\n        grad = lovasz_grad(gt_sorted)\n        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n        return loss\n\n    # deal with the void prediction case (only void pixels)\n    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n                   lambda: tf.reduce_sum(logits) * 0.,\n                   compute_loss,\n                   strict=True,\n                   name=\"loss\"\n                   )\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = tf.reshape(scores, (-1,))\n    labels = tf.reshape(labels, (-1,))\n    if ignore is None:\n        return scores, labels\n    valid = tf.not_equal(labels, ignore)\n    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n    return vscores, vlabels\n\n\n# --------------------------- MULTICLASS LOSSES ---------------------------\n\n\ndef lovasz_softmax(probas, labels, classes='all', per_image=False, ignore=None, order='BHWC'):\n    \"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [B, H, W, C] or [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n      per_image: compute the loss per image instead of per batch\n      ignore: void class labels\n      order: use BHWC or BCHW\n    \"\"\"\n    if per_image:\n        def treat_image(prob_lab):\n            prob, lab = prob_lab\n            prob, lab = tf.expand_dims(prob, 0), tf.expand_dims(lab, 0)\n            prob, lab = flatten_probas(prob, lab, ignore, order)\n            return lovasz_softmax_flat(prob, lab, classes=classes)\n        losses = tf.map_fn(treat_image, (probas, labels), dtype=tf.float32)\n        loss = tf.reduce_mean(losses)\n    else:\n        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore, order), classes=classes)\n    return loss\n\n\ndef lovasz_softmax_flat(probas, labels, classes='all'):\n    \"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n    \"\"\"\n    C = 1\n    losses = []\n    present = []\n    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n    for c in class_to_sum:\n        fg = tf.cast(tf.equal(labels, c), probas.dtype)  # foreground for class c\n        if classes == 'present':\n            present.append(tf.reduce_sum(fg) > 0)\n        errors = tf.abs(fg - probas[:, c])\n        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort_{}\".format(c))\n        fg_sorted = tf.gather(fg, perm)\n        grad = lovasz_grad(fg_sorted)\n        losses.append(\n            tf.tensordot(errors_sorted, tf.stop_gradient(grad), 1, name=\"loss_class_{}\".format(c))\n                      )\n    if len(class_to_sum) == 1:  # short-circuit mean when only one class\n        return losses[0]\n    losses_tensor = tf.stack(losses)\n    if classes == 'present':\n        present = tf.stack(present)\n        losses_tensor = tf.boolean_mask(losses_tensor, present)\n    loss = tf.reduce_mean(losses_tensor)\n    return loss\n\n\ndef flatten_probas(probas, labels, ignore=None, order='BHWC'):\n    \"\"\"\n    Flattens predictions in the batch\n    \"\"\"\n    if order == 'BCHW':\n        probas = tf.transpose(probas, (0, 2, 3, 1), name=\"BCHW_to_BHWC\")\n        order = 'BHWC'\n    if order != 'BHWC':\n        raise NotImplementedError('Order {} unknown'.format(order))\n    C = 1\n    probas = tf.reshape(probas, (-1, C))\n    labels = tf.reshape(labels, (-1,))\n    if ignore is None:\n        return probas, labels\n    valid = tf.not_equal(labels, ignore)\n    vprobas = tf.boolean_mask(probas, valid, name='valid_probas')\n    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n    return vprobas, vlabels\n\ndef keras_lovasz_softmax(labels,probas):\n    #return lovasz_softmax(probas, labels)+binary_crossentropy(labels, probas)\n    return lovasz_softmax(probas, labels)\n\ndef keras_lovasz_hinge(labels,logits):\n    return lovasz_hinge(logits, labels, per_image=True, ignore=None)\n\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "855f438cd862c0d559271be924655e09dd3dcae1"
      },
      "cell_type": "code",
      "source": "# Build model\ndef build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n    # 101 -> 50\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = Activation(ACTIVATION)(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(DropoutRatio/2)(pool1)\n\n    # 50 -> 25\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = Activation(ACTIVATION)(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(DropoutRatio)(pool2)\n\n    # 25 -> 12\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = Activation(ACTIVATION)(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(DropoutRatio)(pool3)\n\n    # 12 -> 6\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = Activation(ACTIVATION)(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(DropoutRatio)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = Activation(ACTIVATION)(convm)\n    \n    # 6 -> 12\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(DropoutRatio)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = Activation(ACTIVATION)(uconv4)\n    \n    # 12 -> 25\n    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(DropoutRatio)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = Activation(ACTIVATION)(uconv3)\n\n    # 25 -> 50\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n        \n    uconv2 = Dropout(DropoutRatio)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = Activation(ACTIVATION)(uconv2)\n    \n    # 50 -> 101\n    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    \n    uconv1 = Dropout(DropoutRatio)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = Activation(ACTIVATION)(uconv1)\n    \n    uconv1 = Dropout(DropoutRatio/2)(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return output_layer",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ec756d6ee036efe05e9a7656140aac8f4b8eb42d"
      },
      "cell_type": "code",
      "source": "thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n\ndef iou(img_true, img_pred):\n    i = np.sum((img_true*img_pred) >0)\n    u = np.sum((img_true + img_pred) >0)\n    if u == 0:\n        return u\n    return i/u\n\ndef iou_metric(imgs_true, imgs_pred):\n    num_images = len(imgs_true)\n    scores = np.zeros(num_images)\n    \n    for i in range(num_images):\n        if imgs_true[i].sum() == imgs_pred[i].sum() == 0:\n            scores[i] = 1\n        else:\n            scores[i] = (thresholds <= iou(imgs_true[i], imgs_pred[i])).mean()\n            \n    return scores.mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19ebf9dd4e697be7d6cce2e90b89edc63f3b852b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Data augmentation\nx_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\nprint(x_train.shape)\nprint(y_valid.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e34e696dbd29eece16f0793b468fb8b29d40a437",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# model\ninput_layer = Input((img_size_target, img_size_target, 1))\n#output_layer = build_model(input_layer, 16,0.5)\noutput_layer = build_model(input_layer, 16,0.2)\n\nmodel = Model(input_layer, output_layer)\nmodel.compile(loss=keras_lovasz_hinge, optimizer=\"adam\", metrics=[\"acc\"])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e720630bfd85acc17366d08a316c7ab23b8a30dd",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "\"\"\"early_stopping = EarlyStopping(monitor='val_acc', mode = 'max',patience=20, verbose=1)\nmodel_checkpoint = ModelCheckpoint(\"./unet_best1.model\",monitor='val_acc', \n                                   mode = 'max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', mode = 'max',factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n#reduce_lr = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=0.00001, verbose=1)\"\"\"\n\nearly_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=20, verbose=1)\nmodel_checkpoint = ModelCheckpoint(\"./unet_best1.model\",monitor='val_my_iou_metric', \n                                   mode = 'max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.1, patience=5, min_lr=0.0005, verbose=1)\n\nepochs = 200\nbatch_size = 32\n\nhistory = model.fit(x_train, y_train,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n                    verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "337090d10ca5f7a92d8014eb8736c9b4b499bfec"
      },
      "cell_type": "code",
      "source": "model = load_model(\"./unet_best1.model\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "134b87cb8c46d714cc0836a36d492c6af07d2c34"
      },
      "cell_type": "code",
      "source": "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n    preds_test += np.array([ np.fliplr(a) for a in model.predict(np.array([np.fliplr(x) for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n    return preds_test/2.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d1f1465164dda4816c6a18dc1ab832dba37ee8c8"
      },
      "cell_type": "code",
      "source": "preds_valid = predict_result(model,x_valid,img_size_target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ef2d20f07e7e67621211fd3596a5e9a64086f22a"
      },
      "cell_type": "code",
      "source": "def filter_image(img):\n    if img.sum() < 100:\n        return np.zeros(img.shape)\n    else:\n        return img\n\n## Scoring for last model\nthresholds = np.linspace(0.3, 0.7, 31)\nious = np.array([iou_metric(y_valid.reshape((-1, img_size_target, img_size_target)), [filter_image(img) for img in preds_valid > threshold]) for threshold in tqdm_notebook(thresholds)])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "6b94f42147fc510d31e6f1dbc423b97a58baefc6"
      },
      "cell_type": "code",
      "source": "threshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9f22db1e8018d910d44cc1fd58cedf20cdd9b265"
      },
      "cell_type": "code",
      "source": "def rle_encode(im):\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4492782c64a195b7f919fce3f9fe2acb0cd5e0ce"
      },
      "cell_type": "code",
      "source": "import gc\n\ndel x_train, x_valid, y_train, y_valid, preds_valid\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d9b24016d92f5de2554817d2a1d16cb9e9fc3e66"
      },
      "cell_type": "code",
      "source": "x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n\npreds_test = predict_result(model,x_test,img_size_target)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "76696763617d19ee7053bcf106f6394f8ecb2714"
      },
      "cell_type": "code",
      "source": "import time\nt1 = time.time()\npred_dict = {idx: rle_encode(filter_image(preds_test[i] > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\nt2 = time.time()\n\nprint(f\"Usedtime = {t2-t1} s\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "eec022d6f13f10f47bfeac3f5ef1e115835b8fed"
      },
      "cell_type": "code",
      "source": "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')\n\n\ntimestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\nprint('Submission output to: sub-Unet-ResNet-797-{}.csv'.format(timestamp))\nsub.to_csv(\"809-Lovasz-Adam-ep200-bs32-lr0005--{}.csv\".format(timestamp))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "5ef05a0d45c996b7dc07b4ca474393cc74c57fa1"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ee9356cc4f09bd9e0d2ec2ce11c4ba933d15fee8"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "fa8449ac25cd01a2e5270c6f4f5d200554138797"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "115ad0c79a3533271e13cc1535603cbfb61983fd"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9727fa4b1b4f3fda179e41a10c39f0808e1877b9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8750ef0f366dae3a5c0aa554c011dcdd67b7c2e2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "5174c0fdc92c8ddc9f35da49581bf722daa66000"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "17925282c9b2574ddcd92ba2c5ed0484cc4c9666"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "84013bd7bd2aaec1529e43ad93a2106cf5137562"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a83db57f9a0a3a7bf7e5eacfef9e1fea0a784ae2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "320613a4ae12885de0ad889304f381262d5e6549"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a21754ed48b7e58b7247fef3455d9701dfefa722"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1cdd9f4db5d0cfa1abfb3ee1e30b222acca02f1b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}