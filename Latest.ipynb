{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from salt_parser import SaltParser\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "# del backbone.losses\n",
    "from backbone.losses import my_iou_metric, my_iou_metric_2, lovasz_loss, focal_loss\n",
    "\n",
    "from net import UResNet34\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import load_model\n",
    "from keras import Model\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128, 128)\n",
    "pretrain_used = True  # ResNet 34\n",
    "normalize = True\n",
    "\n",
    "# Input dictionary for SaltParser\n",
    "salt_parameters = {\n",
    "    'salt_parameters_padding': {\n",
    "        'data_src': './input/',\n",
    "        'image_size': image_size,\n",
    "        'pad_images': True,\n",
    "        'grayscale': False,\n",
    "    },\n",
    "\n",
    "    'salt_parameters_rescale': {\n",
    "        'data_src': './input/',\n",
    "        'image_size': image_size,\n",
    "        'pad_images': False,\n",
    "        'grayscale': False,\n",
    "    }\n",
    "}\n",
    "\n",
    "salt_parsers_padding = SaltParser(**salt_parameters['salt_parameters_padding'])\n",
    "salt_parsers_rescale = SaltParser(**salt_parameters['salt_parameters_rescale'])\n",
    "\n",
    "parsers = {\n",
    "    'padding': salt_parsers_padding,\n",
    "#     'rescale': salt_parsers_rescale\n",
    "}\n",
    "\n",
    "for key in parsers:\n",
    "    parser = parsers[key]\n",
    "    print(key, parser)\n",
    "    parser.initialize_data()\n",
    "    X_train, y_train, X_test = parser.load_data()\n",
    "    train_df = parser.compute_coverage()\n",
    "    padding_pixels = parser.return_padding_borders()\n",
    "\n",
    "    if normalize:\n",
    "        X_train = X_train / 255.\n",
    "        y_train = y_train / 255.\n",
    "        X_test = X_test / 255.\n",
    "        print('X_train - min: {}, max: {}'.format(np.min(X_train), np.max(X_train)))\n",
    "        print('y_train - min: {}, max: {}'.format(np.min(y_train), np.max(y_train)))\n",
    "        print('Train set: {}, {}'.format(X_train.shape, y_train.shape))\n",
    "        print('X_test - min: {}, max: {}'.format(np.min(X_test), np.max(X_test)))\n",
    "        print('Test set: {}'.format(X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    parser.train_df['X_train'] = list(X_train)\n",
    "    parser.train_df['y_train'] = list(y_train)\n",
    "    parser.X_test = X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_1d = lambda x: np.array(x.tolist()).reshape(-1, *image_size, 1)\n",
    "convert_3d = lambda x: np.array(x.tolist()).reshape(-1, *image_size, 3)\n",
    "\n",
    "\n",
    "def get_train_val(n_fold_data, fold_idx):\n",
    "    train = pd.concat([_ for idx, _ in enumerate(n_fold_data) if idx != fold_idx])\n",
    "    valid = n_fold_data[fold_idx]\n",
    "    print(Counter(train.coverage_class))\n",
    "    print(Counter(valid.coverage_class))\n",
    "    x_train = convert_3d(train['X_train'])\n",
    "    x_valid = convert_3d(valid['X_train'])\n",
    "    y_train = convert_1d(train['y_train'])\n",
    "    y_valid = convert_1d(valid['y_train'])\n",
    "    return x_train, x_valid, y_train, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in parsers:\n",
    "    parser = parsers[key]\n",
    "    train_df = parser.train_df\n",
    "\n",
    "    n_fold = 4\n",
    "    train_df.sort_values('coverage_class', inplace=True)\n",
    "    train_df['fold'] = (list(range(n_fold)) * train_df.shape[0])[:train_df.shape[0]]\n",
    "    subsets = [train_df[train_df['fold'] == i] for i in range(n_fold)]\n",
    "    for idx in range(n_fold):\n",
    "        print('\\n\\nNow training fold {} of {}'.format(idx + 1, key))\n",
    "        x_train, x_valid, y_train, y_valid = get_train_val(subsets, idx)\n",
    "        x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "        y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "\n",
    "        adam = Adam(lr=0.001)\n",
    "        model = UResNet34(input_shape=(128, 128, 3))\n",
    "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[my_iou_metric])\n",
    "\n",
    "        # from snapshot import SnapshotCallbackBuilder\n",
    "\n",
    "        # n_snapshots = 5 # number of snapshots\n",
    "        epochs = 30  # number of epochs\n",
    "        # alpha_zero = 0.05 # initial learning rate\n",
    "\n",
    "        # snapshot = SnapshotCallbackBuilder(epochs, n_snapshots, alpha_zero)\n",
    "        # snapshot_ens = snapshot.get_callbacks(model_prefix='ResNet34UNet_')\n",
    "        # early_stopping = EarlyStopping(monitor='my_iou_metric',patience=25,mode='max', verbose=1)\n",
    "        model_checkpoint = ModelCheckpoint(\"./ResUNet34-Fold{}-{}.model\".format(idx + 1, key.capitalize()),\n",
    "                                           monitor='my_iou_metric', mode='max', save_best_only=True, verbose=1)\n",
    "#         reduce_lr = ReduceLROnPlateau(factor=0.25, monitor='my_iou_metric', mode='max', patience=8, verbose=1)\n",
    "\n",
    "        batch_size = 32\n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            validation_data=[x_valid, y_valid],\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[model_checkpoint], shuffle=True,\n",
    "                            verbose=2)  # reduce_lr, model_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Lovasz Loss\n",
    "\n",
    "for key in parsers:\n",
    "    parser = parsers[key]\n",
    "    train_df = parser.train_df\n",
    "\n",
    "    n_fold = 4\n",
    "    if 'fold' not in train_df.columns:\n",
    "        train_df.sort_values('coverage_class', inplace=True)\n",
    "        train_df['fold'] = (list(range(n_fold)) * train_df.shape[0])[:train_df.shape[0]]\n",
    "    subsets = [train_df[train_df['fold'] == i] for i in range(n_fold)]\n",
    "    for idx in range(n_fold):\n",
    "        print('\\n\\nNow training fold {} of {}'.format(idx + 1, key))\n",
    "        x_train, x_valid, y_train, y_valid = get_train_val(subsets, idx)\n",
    "        x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "        y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "\n",
    "        # Load stage 1 model\n",
    "        model_stage_1 = load_model('./ResUNet34-Fold{}-{}.model'.format(idx + 1, key.capitalize()),\n",
    "                                   custom_objects={'my_iou_metric': my_iou_metric})\n",
    "        print('Loaded stage 1 model for', 'ResUNet34-Fold{}-{}.model'.format(idx + 1, key.capitalize()))\n",
    "        # remove layter activation layer and use losvasz loss\n",
    "        input_x = model_stage_1.layers[0].input\n",
    "\n",
    "        output_layer = model_stage_1.layers[-1].input\n",
    "        model = Model(input_x, output_layer)\n",
    "        c = SGD(lr=0.005, decay=0.0001, momentum=0.9)\n",
    "\n",
    "        # lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "        # Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "        model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "        # from snapshot import SnapshotCallbackBuilder\n",
    "\n",
    "        # n_snapshots = 5 # number of snapshots\n",
    "        epochs = 96  # number of epochs\n",
    "        # alpha_zero = 0.05 # initial learning rate\n",
    "        early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode='max', patience=12, verbose=1)\n",
    "        # snapshot = SnapshotCallbackBuilder(epochs, n_snapshots, alpha_zero)\n",
    "        # snapshot_ens = snapshot.get_callbacks(model_prefix='ResNet34UNet_')\n",
    "        # early_stopping = EarlyStopping(monitor='my_iou_metric',patience=25,mode='max', verbose=1)\n",
    "        model_checkpoint = ModelCheckpoint(\"./ResUNet34-Lovasz-Fold{}-{}.model\".format(idx + 1, key.capitalize()),\n",
    "                                           monitor='val_my_iou_metric_2', mode='max', save_best_only=True, verbose=1)\n",
    "        reduce_lr = ReduceLROnPlateau(factor=0.5, monitor='val_my_iou_metric_2', mode='max', patience=6, verbose=1,\n",
    "                                      min_lr=0.0001)\n",
    "\n",
    "        batch_size = 32\n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            validation_data=[x_valid, y_valid],\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[reduce_lr, model_checkpoint], shuffle=True,\n",
    "                            verbose=1)  # reduce_lr, model_checkpoint\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)\n",
    "\n",
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./ResUNet34-Lovasz-Fold1-Padding.model\",custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n",
    "preds_valid = predict_result(model,x_valid,128)\n",
    "\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm(thresholds)])\n",
    "print(ious)\n",
    "\n",
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "threshold_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(parsers['padding'].X_test)\n",
    "\n",
    "y_pred_test_rle = parsers['padding'].predictions_rle_encode(\n",
    "    y_pred_test, confidence_threshold_best=threshold_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = parsers['padding'].generate_submission(y_pred_test_rle)\n",
    "\n",
    "# Save submission with specified run_name.\n",
    "# if save:\n",
    "submission.to_csv('N123ew-submission_{}.csv'.format(1))\n",
    "    \n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
